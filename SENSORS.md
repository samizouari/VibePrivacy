# Capteurs et Syst√®me de D√©tection

## üìπ 1. Cam√©ra Frontale

### Objectifs
- D√©tection de visages multiples dans l'environnement
- Reconnaissance propri√©taire vs inconnu
- Estimation de distance des visages
- Eye-tracking l√©ger pour d√©tection de regard
- Analyse comportementale (approche lente vs rapide)

### Sp√©cifications Techniques

```kotlin
object CameraConfig {
    const val RESOLUTION_WIDTH = 320
    const val RESOLUTION_HEIGHT = 240
    const val BASE_FPS = 10
    const val LOW_POWER_FPS = 5
    const val MINIMAL_FPS = 1 // Screen off
    const val FORMAT = ImageFormat.YUV_420_888
}
```

### Pipeline de Traitement

```
1. Capture Frame (320x240 YUV)
   ‚Üì
2. Face Detection (ML Kit)
   ‚îú‚îÄ‚îÄ Nombre de visages
   ‚îú‚îÄ‚îÄ Bounding boxes
   ‚îî‚îÄ‚îÄ Landmarks (yeux, nez, bouche)
   ‚Üì
3. Face Recognition (Custom Model)
   ‚îú‚îÄ‚îÄ Extraction features (128-d vector)
   ‚îú‚îÄ‚îÄ Comparaison avec database
   ‚îî‚îÄ‚îÄ Identification (Owner/Unknown)
   ‚Üì
4. Distance Estimation
   ‚îú‚îÄ‚îÄ Taille du bounding box
   ‚îú‚îÄ‚îÄ Inter-ocular distance
   ‚îî‚îÄ‚îÄ Estimation en cm
   ‚Üì
5. Gaze Estimation
   ‚îú‚îÄ‚îÄ Position des pupilles
   ‚îú‚îÄ‚îÄ Orientation de la t√™te
   ‚îî‚îÄ‚îÄ Direction du regard
   ‚Üì
6. Behavior Analysis
   ‚îú‚îÄ‚îÄ Vitesse d'approche
   ‚îú‚îÄ‚îÄ Temps de fixation
   ‚îî‚îÄ‚îÄ Pattern de mouvement
```

### Mod√®les ML Utilis√©s

#### Face Detection
```kotlin
val faceDetectorOptions = FaceDetectorOptions.Builder()
    .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)
    .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)
    .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
    .setMinFaceSize(0.1f) // 10% de l'image
    .enableTracking() // Track faces across frames
    .build()
```

#### Face Recognition
- Mod√®le custom bas√© sur FaceNet
- Output: 128-dimensional embedding
- Distance metric: Cosine similarity
- Threshold: 0.85 pour match

#### Gaze Estimation
- Input: Eye landmarks + head pose
- Output: (azimuth, elevation) angles
- Pr√©cision: ¬±15 degrees

### Distance Estimation Algorithm

```kotlin
class DistanceEstimator {
    // Constante calibr√©e (distance inter-oculaire moyenne: 63mm)
    private const val AVERAGE_IPD_MM = 63f
    
    // Focal length estim√©e de la cam√©ra frontale
    private const val FOCAL_LENGTH_PX = 500f
    
    fun estimateDistance(leftEye: PointF, rightEye: PointF): Float {
        // Distance inter-oculaire en pixels
        val ipdPixels = sqrt(
            (rightEye.x - leftEye.x).pow(2) + 
            (rightEye.y - leftEye.y).pow(2)
        )
        
        // Formule de triangulation
        val distanceMm = (AVERAGE_IPD_MM * FOCAL_LENGTH_PX) / ipdPixels
        
        return distanceMm / 10f // Convertir en cm
    }
}
```

### Output Data Structure

```kotlin
data class CameraDetectionResult(
    val timestamp: Long,
    val faces: List<DetectedFace>,
    val ownerPresent: Boolean,
    val unknownFaceCount: Int,
    val closestFaceDistance: Float, // cm
    val threatLevel: Float // 0-1
)

data class DetectedFace(
    val trackingId: Int,
    val boundingBox: Rect,
    val distance: Float,
    val isOwner: Boolean,
    val gazeDirection: GazeDirection,
    val approachSpeed: Float, // cm/s
    val fixationDuration: Long // ms
)

enum class GazeDirection {
    AT_SCREEN,      // Regarde l'√©cran
    AWAY,           // Regarde ailleurs
    GLANCING,       // Coup d'≈ìil rapide
    STARING         // Fixation prolong√©e
}
```

### Optimisations

**Adaptive Frame Rate:**
```kotlin
class AdaptiveCameraManager {
    fun computeOptimalFps(context: DeviceContext): Int {
        return when {
            !context.screenOn -> 1
            context.batteryLevel < 15 -> 3
            context.powerSaveMode -> 5
            context.isCharging -> 15
            context.thermalState == CRITICAL -> 3
            else -> 10
        }
    }
}
```

**Region of Interest:**
```kotlin
// Concentrer l'analyse sur zone √† risque
val roi = when (screenOrientation) {
    PORTRAIT -> Rect(0, 0, width, height / 2) // Moiti√© sup√©rieure
    LANDSCAPE -> Rect(0, 0, width, height) // Tout l'√©cran
}
```

## üé§ 2. Microphone

### Objectifs
- D√©tection de voix multiples
- Patterns audio sp√©cifiques (pas, porte, chuchotements)
- Mots-cl√©s suspects
- Analyse de proximit√© sonore
- D√©tection de changements d'ambiance

### Sp√©cifications Techniques

```kotlin
object AudioConfig {
    const val SAMPLE_RATE = 16000 // Hz (suffisant pour voix)
    const val CHANNEL = AudioFormat.CHANNEL_IN_MONO
    const val ENCODING = AudioFormat.ENCODING_PCM_16BIT
    const val CHUNK_SIZE_MS = 100 // Analyse par chunks de 100ms
    const val BUFFER_SIZE_MS = 3000 // Buffer circulaire 3s
}
```

### Pipeline de Traitement

```
1. Audio Capture (16kHz, Mono)
   ‚Üì
2. Pre-processing
   ‚îú‚îÄ‚îÄ Noise Reduction
   ‚îú‚îÄ‚îÄ Normalization
   ‚îî‚îÄ‚îÄ VAD (Voice Activity Detection)
   ‚Üì
3. Feature Extraction
   ‚îú‚îÄ‚îÄ MFCC (Mel-Frequency Cepstral Coefficients)
   ‚îú‚îÄ‚îÄ Spectral features
   ‚îî‚îÄ‚îÄ Temporal features
   ‚Üì
4. Analysis
   ‚îú‚îÄ‚îÄ Voice Counting (Speaker Diarization)
   ‚îú‚îÄ‚îÄ Keyword Spotting (TFLite model)
   ‚îú‚îÄ‚îÄ Pattern Detection (FFT analysis)
   ‚îî‚îÄ‚îÄ Proximity Estimation (Volume + freq)
   ‚Üì
5. Threat Assessment
```

### Voice Counting

```kotlin
class VoiceCounter {
    private val speakerEmbedding = SpeakerEmbeddingModel()
    
    fun countVoices(audioChunks: List<FloatArray>): Int {
        val embeddings = audioChunks
            .filter { hasVoiceActivity(it) }
            .map { chunk -> speakerEmbedding.extract(chunk) }
        
        // Clustering des embeddings
        val clusters = dbscan(embeddings, eps = 0.3, minSamples = 2)
        
        return clusters.size
    }
}
```

### Keyword Spotting

**Mots-cl√©s suspects configurables:**
```kotlin
val suspiciousKeywords = listOf(
    // Fran√ßais
    "regarde", "qu'est-ce que tu fais", "montre-moi", 
    "c'est quoi", "tu fais quoi", "laisse-moi voir",
    
    // Anglais
    "look", "what are you doing", "show me",
    "let me see", "what's that",
    
    // Contextuels
    "police", "contr√¥le", "v√©rification"
)
```

**Impl√©mentation:**
```kotlin
class KeywordSpotter {
    private val model = loadTFLiteModel("keyword_spotting.tflite")
    
    fun detect(audioFeatures: FloatArray): List<DetectedKeyword> {
        val scores = model.run(audioFeatures)
        
        return keywords.indices
            .filter { scores[it] > CONFIDENCE_THRESHOLD }
            .map { DetectedKeyword(keywords[it], scores[it]) }
    }
}
```

### Pattern Detection

```kotlin
enum class SoundPattern(val description: String) {
    FOOTSTEPS("Pas qui s'approchent"),
    DOOR_OPENING("Porte qui s'ouvre"),
    DOOR_CLOSING("Porte qui se ferme"),
    CHAIR_MOVING("Chaise qui bouge"),
    WHISPER("Chuchotement"),
    CROWD("Foule/groupe de personnes"),
    SILENCE("Silence soudain suspect"),
    KEYBOARD("Frappe clavier (quelqu'un travaille √† c√¥t√©)")
}

class PatternDetector {
    fun detect(audioBuffer: FloatArray): List<SoundPattern> {
        val fft = computeFFT(audioBuffer)
        val spectralCentroid = computeSpectralCentroid(fft)
        val zeroCrossingRate = computeZCR(audioBuffer)
        val rmsEnergy = computeRMS(audioBuffer)
        
        return buildList {
            // Footsteps: low freq, periodic
            if (detectPeriodicity(fft, 1.5f..2.5f)) {
                add(SoundPattern.FOOTSTEPS)
            }
            
            // Door: sudden broadband noise + decay
            if (detectImpulse(audioBuffer) && hasDecay(rmsEnergy)) {
                add(SoundPattern.DOOR_OPENING)
            }
            
            // Whisper: high ZCR, low energy, mid-high freq
            if (zeroCrossingRate > 0.3f && rmsEnergy < 0.1f && spectralCentroid > 2000) {
                add(SoundPattern.WHISPER)
            }
            
            // Silence soudain (suspect)
            if (rmsEnergy < 0.05f && previousRmsEnergy > 0.2f) {
                add(SoundPattern.SILENCE)
            }
        }
    }
}
```

### Proximity Estimation

```kotlin
class AudioProximityEstimator {
    fun estimate(audioLevel: Float, frequency: Float): ProximityLevel {
        // Sons proches: volume √©lev√© + fr√©quences aigu√´s pr√©serv√©es
        return when {
            audioLevel > 0.7f && frequency > 4000 -> ProximityLevel.VERY_CLOSE
            audioLevel > 0.5f && frequency > 2000 -> ProximityLevel.CLOSE
            audioLevel > 0.3f -> ProximityLevel.MEDIUM
            else -> ProximityLevel.FAR
        }
    }
}
```

### Output Data Structure

```kotlin
data class AudioDetectionResult(
    val timestamp: Long,
    val voiceCount: Int,
    val detectedKeywords: List<DetectedKeyword>,
    val soundPatterns: List<SoundPattern>,
    val proximityLevel: ProximityLevel,
    val ambientNoiseLevel: Float,
    val threatLevel: Float
)

data class DetectedKeyword(
    val keyword: String,
    val confidence: Float,
    val timestamp: Long
)
```

## üì± 3. Acc√©l√©rom√®tre + Gyroscope

### Objectifs
- D√©tection mouvements brusques
- Changements d'orientation soudains
- D√©tection de "peek" (soulever/reposer rapidement)
- T√©l√©phone retourn√©
- Vibrations inhabituelles

### Sp√©cifications Techniques

```kotlin
object MotionConfig {
    const val SAMPLE_RATE = 50 // Hz
    const val BUFFER_SIZE = 100 // 2 secondes de donn√©es
    const val GRAVITY = 9.81f // m/s¬≤
}
```

### Sensor Fusion

```kotlin
class SensorFusion {
    private val kalmanFilter = KalmanFilter()
    
    fun fuse(
        accel: FloatArray,
        gyro: FloatArray,
        timestamp: Long
    ): FusedMotionData {
        // Filtrage Kalman pour r√©duire bruit
        val filteredAccel = kalmanFilter.filter(accel)
        val filteredGyro = kalmanFilter.filter(gyro)
        
        // Calcul de l'orientation
        val orientation = computeOrientation(filteredAccel, filteredGyro)
        
        // D√©tection de mouvement
        val movement = detectMovement(filteredAccel, filteredGyro)
        
        return FusedMotionData(
            acceleration = filteredAccel,
            angularVelocity = filteredGyro,
            orientation = orientation,
            movement = movement,
            timestamp = timestamp
        )
    }
}
```

### Gesture Detection

```kotlin
class GestureDetector {
    fun detect(motionHistory: List<FusedMotionData>): MotionGesture? {
        return when {
            detectSuddenMovement(motionHistory) -> MotionGesture.SUDDEN_GRAB
            detectFlip(motionHistory) -> MotionGesture.PHONE_FLIPPED
            detectPeek(motionHistory) -> MotionGesture.PEEK
            detectDrop(motionHistory) -> MotionGesture.DROPPED
            detectShake(motionHistory) -> MotionGesture.SHAKE
            detectRotation(motionHistory) -> MotionGesture.ROTATION
            else -> null
        }
    }
    
    private fun detectSuddenMovement(history: List<FusedMotionData>): Boolean {
        // Acc√©l√©ration soudaine > 20 m/s¬≤
        val recentAccel = history.takeLast(10)
        val maxAccel = recentAccel.maxOf { it.acceleration.magnitude() }
        return maxAccel > 20f
    }
    
    private fun detectPeek(history: List<FusedMotionData>): Boolean {
        // Pattern: soulev√© rapidement puis repos√©
        // 1. Acc√©l√©ration vers le haut
        // 2. Stabilisation br√®ve (< 500ms)
        // 3. D√©c√©l√©ration vers le bas
        
        if (history.size < 50) return false
        
        val last2Seconds = history.takeLast(100)
        val hasUpwardAccel = last2Seconds.take(30).any { 
            it.acceleration[2] > 12f // Z-axis
        }
        val hasDownwardAccel = last2Seconds.takeLast(30).any {
            it.acceleration[2] < 8f
        }
        val briefStable = last2Seconds.subList(30, 70).all {
            abs(it.acceleration[2] - GRAVITY) < 2f
        }
        
        return hasUpwardAccel && briefStable && hasDownwardAccel
    }
    
    private fun detectFlip(history: List<FusedMotionData>): Boolean {
        // Changement d'orientation de 180¬∞ en Z
        val first = history.first().orientation
        val last = history.last().orientation
        val angleDiff = abs(last.z - first.z)
        return angleDiff > 160f && angleDiff < 200f
    }
}
```

### Output Data Structure

```kotlin
data class MotionDetectionResult(
    val timestamp: Long,
    val gesture: MotionGesture?,
    val orientation: Orientation,
    val isStable: Boolean,
    val vibrationLevel: Float,
    val threatLevel: Float
)

enum class MotionGesture {
    SUDDEN_GRAB,    // Quelqu'un attrape le t√©l√©phone
    PHONE_FLIPPED,  // Retourn√© face cach√©e
    PEEK,           // Soulev√© puis repos√© rapidement
    DROPPED,        // Tomb√©
    SHAKE,          // Secou√©
    ROTATION        // Rotation rapide
}
```

## üîç 4. Capteur de Proximit√©

### Objectifs
- D√©tection d'objets proches de l'√©cran
- Main qui passe devant
- Occultation r√©p√©t√©e (quelqu'un essaie de voir)

### Impl√©mentation

```kotlin
class ProximityWatcher(private val sensor: Sensor) {
    private val occultationHistory = CircularBuffer<Long>(capacity = 10)
    
    fun onSensorChanged(event: SensorEvent) {
        val distance = event.values[0] // cm
        val isNear = distance < sensor.maximumRange * 0.2f // < 20% de la port√©e max
        
        if (isNear) {
            occultationHistory.add(System.currentTimeMillis())
            
            // D√©tection d'occultation r√©p√©t√©e
            if (isRapidOccultation()) {
                onThreatDetected(ThreatType.RAPID_OCCULTATION)
            }
        }
    }
    
    private fun isRapidOccultation(): Boolean {
        // 3+ occultations en moins de 5 secondes
        if (occultationHistory.size < 3) return false
        
        val timespan = occultationHistory.last() - occultationHistory.first()
        return timespan < 5000 // ms
    }
}
```

## üí° 5. Capteur de Luminosit√©

### Objectifs
- D√©tection d'ombres (personne qui se penche)
- Changements brusques d'exposition

### Impl√©mentation

```kotlin
class LightSensorAnalyzer {
    private val lightHistory = CircularBuffer<Float>(capacity = 50)
    
    fun analyze(lightLevel: Float): LightDetectionResult {
        lightHistory.add(lightLevel)
        
        val shadowDetected = detectShadow(lightLevel)
        val suddenChange = detectSuddenChange(lightLevel)
        
        return LightDetectionResult(
            timestamp = System.currentTimeMillis(),
            shadowDetected = shadowDetected,
            suddenChange = suddenChange,
            lightLevel = lightLevel,
            changeRate = computeChangeRate(),
            threatLevel = computeThreatLevel(shadowDetected, suddenChange)
        )
    }
    
    private fun detectShadow(current: Float): Boolean {
        if (lightHistory.size < 10) return false
        
        val baseline = lightHistory.takeLast(10).average()
        val dropPercentage = (baseline - current) / baseline
        
        // Baisse de 30%+ = ombre
        return dropPercentage > 0.3f
    }
    
    private fun detectSuddenChange(current: Float): Boolean {
        if (lightHistory.size < 2) return false
        
        val previous = lightHistory[lightHistory.size - 2]
        val changeMagnitude = abs(current - previous) / previous
        
        // Changement de 50%+ en 1 sample
        return changeMagnitude > 0.5f
    }
}
```

## üìç 6. GPS + G√©ofencing

### Objectifs
- D√©finir zones √† haut risque
- Adaptation automatique de la sensibilit√©
- Apprentissage des lieux fr√©quents

### Impl√©mentation

```kotlin
class LocationMonitor {
    private val geofencingClient = LocationServices.getGeofencingClient(context)
    
    fun setupGeofences(zones: List<TrustZone>) {
        val geofences = zones.map { zone ->
            Geofence.Builder()
                .setRequestId(zone.id.toString())
                .setCircularRegion(zone.latitude, zone.longitude, zone.radius)
                .setExpirationDuration(Geofence.NEVER_EXPIRE)
                .setTransitionTypes(
                    Geofence.GEOFENCE_TRANSITION_ENTER or
                    Geofence.GEOFENCE_TRANSITION_EXIT
                )
                .build()
        }
        
        geofencingClient.addGeofences(
            GeofencingRequest.Builder()
                .setInitialTrigger(GeofencingRequest.INITIAL_TRIGGER_ENTER)
                .addGeofences(geofences)
                .build(),
            geofencePendingIntent
        )
    }
    
    fun onGeofenceTransition(geofenceTransition: GeofencingEvent) {
        when (geofenceTransition.geofenceTransition) {
            Geofence.GEOFENCE_TRANSITION_ENTER -> {
                val zone = getZoneById(geofenceTransition.triggeringGeofences[0].requestId)
                applyZoneSettings(zone)
            }
            Geofence.GEOFENCE_TRANSITION_EXIT -> {
                resetToDefaultSettings()
            }
        }
    }
}
```

### Auto-Learning Locations

```kotlin
class LocationLearner {
    fun learnFrequentLocations() {
        val locationHistory = locationDao.getLastMonth()
        
        // Clustering des localisations
        val clusters = dbscan(
            locationHistory.map { Point(it.latitude, it.longitude) },
            eps = 0.001, // ~100m
            minSamples = 10
        )
        
        clusters.forEach { cluster ->
            val centroid = cluster.centroid()
            val visits = cluster.size
            val avgDuration = cluster.map { it.duration }.average()
            
            // Si visit√© souvent et temps long = probable maison/travail
            if (visits > 20 && avgDuration > 30.minutes) {
                suggestTrustZone(
                    location = centroid,
                    type = inferZoneType(cluster),
                    confidence = computeConfidence(visits, avgDuration)
                )
            }
        }
    }
}
```

---

Cette architecture de capteurs fournit une d√©tection multi-modale robuste et adaptative.

